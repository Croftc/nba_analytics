{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dqn agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the DQN model class\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)  # Adjust layer sizes as needed\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the agent class\n",
    "class ParlaysDQNAgent:\n",
    "    def __init__(self, state_size, action_size, batch_size=64, gamma=0.99,\n",
    "                 epsilon_start=0.0, epsilon_end=0.0, epsilon_decay=1.0,\n",
    "                 learning_rate=0.001, target_update=10, memory_size=10000,\n",
    "                 logging_level=logging.INFO):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon_start  # Exploration rate (0 for inference)\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.target_update = target_update  # Episodes between target network updates\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.bankroll = 10000  # Starting bankroll\n",
    "        \n",
    "        # Neural networks\n",
    "        self.policy_net = DQN(state_size, action_size)\n",
    "        self.target_net = DQN(state_size, action_size)\n",
    "        self.update_target_net()\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        # Set up logging\n",
    "        self.logger = logging.getLogger('ParlaysDQNAgent')\n",
    "        self.logger.setLevel(logging_level)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setLevel(logging_level)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        if not self.logger.handlers:\n",
    "            self.logger.addHandler(handler)\n",
    "        self.logger.propagate = False  # Prevent duplicate logs\n",
    "        \n",
    "    def update_target_net(self):\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        pass  # Not used during inference\n",
    "        \n",
    "    def act(self, state, available_actions):\n",
    "        # Since epsilon is 0 during inference, we always exploit\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.policy_net(state_tensor)\n",
    "        q_values = q_values.detach().numpy()[0]\n",
    "        # Mask unavailable actions if necessary\n",
    "        masked_q_values = q_values.copy()\n",
    "        # Select the action with the highest Q-value\n",
    "        action_idx = np.argmax(masked_q_values)\n",
    "        return action_idx, q_values\n",
    "        \n",
    "    def replay(self):\n",
    "        pass  # Not used during inference\n",
    "        \n",
    "    def decay_epsilon(self):\n",
    "        pass  # Not used during inference\n",
    "        \n",
    "    def save_model(self, filepath):\n",
    "        torch.save(self.policy_net.state_dict(), filepath)\n",
    "        \n",
    "    def load_model(self, filepath):\n",
    "        self.policy_net.load_state_dict(torch.load(filepath))\n",
    "        self.update_target_net()\n",
    "        \n",
    "    def american_to_decimal_odds(self, odds):\n",
    "        # Convert American odds to decimal odds\n",
    "        if odds > 0:\n",
    "            return (odds / 100) + 1\n",
    "        else:\n",
    "            return (100 / abs(odds)) + 1\n",
    "\n",
    "# Helper functions\n",
    "def odds_to_implied_prob(odds):\n",
    "    # Convert American odds to implied probability\n",
    "    if odds > 0:\n",
    "        return 100 / (odds + 100)\n",
    "    else:\n",
    "        return abs(odds) / (abs(odds) + 100)\n",
    "\n",
    "def get_state(games_data, bankroll, max_games=15):\n",
    "    # Initialize state with zeros and pad for games < max_games\n",
    "    state = np.zeros((max_games, 2, 4))  # [Games, Teams, Features]\n",
    "    \n",
    "    game_ids = games_data['GAME-ID'].unique()\n",
    "    for i, game_id in enumerate(game_ids):\n",
    "        if i >= max_games:\n",
    "            break  # Only consider up to max_games\n",
    "        \n",
    "        game_df = games_data[games_data['GAME-ID'] == game_id]\n",
    "        teams = game_df['TEAM'].unique()\n",
    "        \n",
    "        for j, team in enumerate(teams):\n",
    "            team_data = game_df[game_df['TEAM'] == team].iloc[0]\n",
    "            # Predicted probabilities\n",
    "            ml_prob = team_data['ml_prob']\n",
    "            spread_prob = team_data['spread_prob']\n",
    "            # Offered odds\n",
    "            ml_odds = team_data['MONEYLINE']\n",
    "            spread_odds = team_data['SPREAD_LINE']\n",
    "            # Implied probabilities\n",
    "            ml_imp_prob = odds_to_implied_prob(ml_odds)\n",
    "            spread_imp_prob = odds_to_implied_prob(spread_odds)\n",
    "            # Value indicators\n",
    "            ml_value = ml_prob - ml_imp_prob\n",
    "            spread_value = spread_prob - spread_imp_prob\n",
    "            # Assign features\n",
    "            state[i, j, :] = [ml_prob, ml_value, spread_prob, spread_value]\n",
    "    \n",
    "    state = state.flatten()\n",
    "    state = np.append(state, bankroll / 10000)  # Normalize bankroll\n",
    "    return state\n",
    "\n",
    "def generate_actions(games_data, stake_sizes=[0.01, 0.02, 0.03, 0.04, 0.05]):\n",
    "    actions = []\n",
    "    game_ids = games_data['GAME-ID'].unique()\n",
    "    for i, game_id in enumerate(game_ids):\n",
    "        game_df = games_data[games_data['GAME-ID'] == game_id]\n",
    "        teams = game_df['TEAM'].unique()\n",
    "        for team in teams:\n",
    "            for market in ['ML', 'Spread']:\n",
    "                line_col = 'MONEYLINE' if market == 'ML' else 'SPREAD_LINE'\n",
    "                for stake in stake_sizes:\n",
    "                    action = {\n",
    "                        'game_index': i,\n",
    "                        'team': team,\n",
    "                        'market': market,\n",
    "                        'stake': stake,\n",
    "                        'line': game_df[game_df['TEAM'] == team][line_col].values[0]\n",
    "                    }\n",
    "                    actions.append(action)\n",
    "    return actions\n",
    "\n",
    "# Load the trained agent and perform inference\n",
    "\n",
    "# Step 1: Load the trained agent\n",
    "# Replace 'state_size' and 'action_size' with the values used during training\n",
    "\n",
    "state_size = (15 * 2 * 4) + 1  # 15 games, 2 teams, 4 features per team, plus bankroll\n",
    "\n",
    "# We need to determine the action size as used during training\n",
    "# For that, we need to generate actions for a sample data to get the action size\n",
    "\n",
    "# Sample data to determine action size\n",
    "sample_data = {\n",
    "    'DATE': ['2024-11-16'] * 30,\n",
    "    'GAME-ID': [i // 2 for i in range(30)],\n",
    "    'TEAM': ['Team' + str(i) for i in range(30)],\n",
    "    'ml_prob': np.random.rand(30),\n",
    "    'ml_result': np.random.choice([True, False], 30),\n",
    "    'MONEYLINE': np.random.randint(-200, 200, 30),\n",
    "    'spread_prob': np.random.rand(30),\n",
    "    'spread_result': np.random.choice([True, False], 30),\n",
    "    'SPREAD_LINE': np.random.randint(-110, 110, 30),\n",
    "}\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "actions = generate_actions(sample_df)\n",
    "action_size = len(actions)\n",
    "\n",
    "# Create the agent\n",
    "agent = ParlaysDQNAgent(\n",
    "    state_size=state_size,\n",
    "    action_size=action_size,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    epsilon_start=0.0,  # Set epsilon to 0 for inference\n",
    "    epsilon_end=0.0,\n",
    "    epsilon_decay=1.0,\n",
    "    learning_rate=0.001,\n",
    "    target_update=10,\n",
    "    memory_size=10000,\n",
    "    logging_level=logging.INFO\n",
    ")\n",
    "\n",
    "# Load the trained model weights\n",
    "agent.load_model('parlays_dqn_model.pth')  # Replace with the path to your saved model\n",
    "\n",
    "# Step 2: Prepare today's game data and state\n",
    "\n",
    "# Replace 'today_games.csv' with your actual data file or DataFrame\n",
    "# Ensure that the DataFrame has all required columns and correct data types\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils import resample  # Added import for resample\n",
    "import joblib\n",
    "\n",
    "class BootstrapCalibratedClassifier:\n",
    "    def __init__(self, n_bootstrap_samples=8, base_model_params=None, gpu_id=0):\n",
    "        \"\"\"\n",
    "        Initializes the BootstrapCalibratedClassifier.\n",
    "\n",
    "        Parameters:\n",
    "        - n_bootstrap_samples (int): Number of bootstrap samples/models.\n",
    "        - base_model_params (dict): Parameters for the XGBoost base model.\n",
    "        - gpu_id (int): GPU device ID to use.\n",
    "        \"\"\"\n",
    "        self.n_bootstrap_samples = n_bootstrap_samples\n",
    "        self.bootstrap_models = []\n",
    "        self.calibrated_models = []\n",
    "        self.gpu_id = gpu_id  # GPU device ID\n",
    "\n",
    "        # Default XGBoost parameters with GPU support\n",
    "        self.base_model_params = base_model_params if base_model_params else {\n",
    "            'tree_method': \"hist\",\n",
    "            'device': 'cuda',\n",
    "            'enable_categorical': True,\n",
    "            'max_depth': 10,\n",
    "            'learning_rate': 0.09937420876401226,\n",
    "            'n_estimators': 12,\n",
    "            'gamma': 0.340466985869831,\n",
    "            'subsample': 0.7222619026651159,\n",
    "            'colsample_bytree': 0.5739321839530654,\n",
    "            'reg_alpha': 0.9462720081810914,\n",
    "            'reg_lambda': 0.5567871265347748\n",
    "            }\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fits the bootstrap and calibrated models on the training data.\n",
    "\n",
    "        Parameters:\n",
    "        - X_train (array-like): Training features.\n",
    "        - y_train (array-like): Training labels.\n",
    "        \"\"\"\n",
    "        for i in range(self.n_bootstrap_samples):\n",
    "            print(f\"Training bootstrap model {i+1}/{self.n_bootstrap_samples} on GPU {self.gpu_id}...\")\n",
    "            \n",
    "            # Bootstrap sample generation\n",
    "            X_train_sample, y_train_sample = resample(X_train, y_train, n_samples=len(X_train), replace=True)\n",
    "            \n",
    "            # Train base model\n",
    "            model = xgb.XGBClassifier(**self.base_model_params)\n",
    "            model.fit(X_train_sample, y_train_sample)\n",
    "            self.bootstrap_models.append(model)\n",
    "            \n",
    "            # Calibrate the model\n",
    "            calibrated_model = CalibratedClassifierCV(model, method='sigmoid', cv='prefit')\n",
    "            calibrated_model.fit(X_train_sample, y_train_sample)\n",
    "            self.calibrated_models.append(calibrated_model)\n",
    "            print(f\"Bootstrap model {i+1} trained and calibrated.\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class labels for samples in X.\n",
    "\n",
    "        Parameters:\n",
    "        - X (array-like): Input features.\n",
    "\n",
    "        Returns:\n",
    "        - array-like: Predicted class labels.\n",
    "        \"\"\"\n",
    "        if not self.bootstrap_models:\n",
    "            raise Exception(\"The model has not been fitted yet.\")\n",
    "        \n",
    "        # Aggregate predictions from bootstrap models\n",
    "        preds = np.array([model.predict(X) for model in self.bootstrap_models])\n",
    "        return np.round(np.mean(preds, axis=0)).astype(int)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"\n",
    "        Predicts class probabilities for samples in X.\n",
    "\n",
    "        Parameters:\n",
    "        - X (array-like): Input features.\n",
    "\n",
    "        Returns:\n",
    "        - array-like: Predicted class probabilities.\n",
    "        \"\"\"\n",
    "        if not self.calibrated_models:\n",
    "            raise Exception(\"The model has not been fitted yet.\")\n",
    "        \n",
    "        # Aggregate calibrated predicted probabilities from bootstrap models\n",
    "        proba = np.array([calibrated_model.predict_proba(X) for calibrated_model in self.calibrated_models])\n",
    "        # Average probabilities across all bootstrap models\n",
    "        return np.mean(proba, axis=0)\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"\n",
    "        Calculates the accuracy score of the model.\n",
    "\n",
    "        Parameters:\n",
    "        - X_test (array-like): Test features.\n",
    "        - y_test (array-like): True labels.\n",
    "\n",
    "        Returns:\n",
    "        - float: Accuracy score.\n",
    "        \"\"\"\n",
    "        predictions = self.predict(X_test)\n",
    "        return accuracy_score(y_test, predictions)\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        \"\"\"\n",
    "        Saves the trained models to files.\n",
    "\n",
    "        Parameters:\n",
    "        - filename (str): Base filename to save the models.\n",
    "        \"\"\"\n",
    "        for idx, model in enumerate(self.bootstrap_models):\n",
    "            model_path = f\"{filename}_model_{idx}.pkl\"\n",
    "            joblib.dump(model, model_path)\n",
    "        \n",
    "        # Save calibrated models\n",
    "        for idx, calibrated_model in enumerate(self.calibrated_models):\n",
    "            calibrated_model_path = f\"{filename}_calibrated_{idx}.pkl\"\n",
    "            joblib.dump(calibrated_model, calibrated_model_path)\n",
    "        print(f\"Models saved to {filename}_model_*.pkl and {filename}_calibrated_*.pkl\")\n",
    "\n",
    "    def load_model(self, filename):\n",
    "        \"\"\"\n",
    "        Loads both base and calibrated models from files.\n",
    "\n",
    "        Parameters:\n",
    "        - filename (str): Base filename from which to load the models.\n",
    "        \"\"\"\n",
    "        self.bootstrap_models = []\n",
    "        self.calibrated_models = []\n",
    "        \n",
    "        for idx in range(self.n_bootstrap_samples):\n",
    "            base_model_path = f\"{filename}_model_{idx}.pkl\"\n",
    "            calibrated_model_path = f\"{filename}_calibrated_{idx}.pkl\"\n",
    "            \n",
    "            try:\n",
    "                base_model = joblib.load(base_model_path)\n",
    "                calibrated_model = joblib.load(calibrated_model_path)\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"Error loading model {idx}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            self.bootstrap_models.append(base_model)\n",
    "            self.calibrated_models.append(calibrated_model)\n",
    "        print(f\"Models loaded from {filename}_model_*.pkl and {filename}_calibrated_*.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import logging\n",
    "from collections import deque\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the DQN model class\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)  # Adjust layer sizes as needed\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Define the agent class\n",
    "class ParlaysDQNAgent:\n",
    "    def __init__(self, state_size, action_size, batch_size=64, gamma=0.99,\n",
    "                 epsilon_start=0.0, epsilon_end=0.0, epsilon_decay=1.0,\n",
    "                 learning_rate=0.001, target_update=10, memory_size=10000,\n",
    "                 logging_level=logging.INFO):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.batch_size = batch_size\n",
    "        self.gamma = gamma  # Discount factor\n",
    "        self.epsilon = epsilon_start  # Exploration rate (0 for inference)\n",
    "        self.epsilon_min = epsilon_end\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.learning_rate = learning_rate\n",
    "        self.target_update = target_update  # Episodes between target network updates\n",
    "        self.memory = deque(maxlen=memory_size)\n",
    "        self.bankroll = 10000  # Starting bankroll\n",
    "        \n",
    "        # Neural networks\n",
    "        self.policy_net = DQN(state_size, action_size)\n",
    "        self.target_net = DQN(state_size, action_size)\n",
    "        self.update_target_net()\n",
    "        \n",
    "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=self.learning_rate)\n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        # Set up logging\n",
    "        self.logger = logging.getLogger('ParlaysDQNAgent')\n",
    "        self.logger.setLevel(logging_level)\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setLevel(logging_level)\n",
    "        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "        handler.setFormatter(formatter)\n",
    "        if not self.logger.handlers:\n",
    "            self.logger.addHandler(handler)\n",
    "        self.logger.propagate = False  # Prevent duplicate logs\n",
    "        \n",
    "    def update_target_net(self):\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        pass  # Not used during inference\n",
    "        \n",
    "    def act(self, state, available_actions):\n",
    "        # Since epsilon is 0 during inference, we always exploit\n",
    "        state_tensor = torch.FloatTensor(state).unsqueeze(0)\n",
    "        with torch.no_grad():\n",
    "            q_values = self.policy_net(state_tensor)\n",
    "        q_values = q_values.detach().numpy()[0]\n",
    "        # Mask unavailable actions if necessary\n",
    "        masked_q_values = q_values.copy()\n",
    "        # Select the action with the highest Q-value\n",
    "        action_idx = np.argmax(masked_q_values)\n",
    "        return action_idx, q_values\n",
    "        \n",
    "    def replay(self):\n",
    "        pass  # Not used during inference\n",
    "        \n",
    "    def decay_epsilon(self):\n",
    "        pass  # Not used during inference\n",
    "        \n",
    "    def save_model(self, filepath):\n",
    "        torch.save(self.policy_net.state_dict(), filepath)\n",
    "        \n",
    "    def load_model(self, filepath):\n",
    "        self.policy_net.load_state_dict(torch.load(filepath))\n",
    "        self.update_target_net()\n",
    "        \n",
    "    def american_to_decimal_odds(self, odds):\n",
    "        # Convert American odds to decimal odds\n",
    "        if odds > 0:\n",
    "            return (odds / 100) + 1\n",
    "        else:\n",
    "            return (100 / abs(odds)) + 1\n",
    "\n",
    "# Helper functions\n",
    "def odds_to_implied_prob(odds):\n",
    "    # Convert American odds to implied probability\n",
    "    if odds > 0:\n",
    "        return 100 / (odds + 100)\n",
    "    else:\n",
    "        return abs(odds) / (abs(odds) + 100)\n",
    "\n",
    "def get_state(games_data, bankroll, max_games=15):\n",
    "    # Initialize state with zeros and pad for games < max_games\n",
    "    state = np.zeros((max_games, 2, 4))  # [Games, Teams, Features]\n",
    "    \n",
    "    game_ids = games_data['GAME-ID'].unique()\n",
    "    for i, game_id in enumerate(game_ids):\n",
    "        if i >= max_games:\n",
    "            break  # Only consider up to max_games\n",
    "        \n",
    "        game_df = games_data[games_data['GAME-ID'] == game_id]\n",
    "        teams = game_df['TEAM'].unique()\n",
    "        \n",
    "        for j, team in enumerate(teams):\n",
    "            team_data = game_df[game_df['TEAM'] == team].iloc[0]\n",
    "            # Predicted probabilities\n",
    "            ml_prob = team_data['ml_prob']\n",
    "            spread_prob = team_data['spread_prob']\n",
    "            # Offered odds\n",
    "            ml_odds = team_data['MONEYLINE']\n",
    "            spread_odds = team_data['SPREAD_LINE']\n",
    "            # Implied probabilities\n",
    "            ml_imp_prob = odds_to_implied_prob(ml_odds)\n",
    "            spread_imp_prob = odds_to_implied_prob(spread_odds)\n",
    "            # Value indicators\n",
    "            ml_value = ml_prob - ml_imp_prob\n",
    "            spread_value = spread_prob - spread_imp_prob\n",
    "            # Assign features\n",
    "            state[i, j, :] = [ml_prob, ml_value, spread_prob, spread_value]\n",
    "    \n",
    "    state = state.flatten()\n",
    "    state = np.append(state, bankroll / 10000)  # Normalize bankroll\n",
    "    return state\n",
    "\n",
    "def generate_actions(games_data, stake_sizes=[0.01, 0.02, 0.03, 0.04, 0.05]):\n",
    "    actions = []\n",
    "    game_ids = games_data['GAME-ID'].unique()\n",
    "    for i, game_id in enumerate(game_ids):\n",
    "        game_df = games_data[games_data['GAME-ID'] == game_id]\n",
    "        teams = game_df['TEAM'].unique()\n",
    "        for team in teams:\n",
    "            for market in ['ML', 'Spread']:\n",
    "                for stake in stake_sizes:\n",
    "                    action = {\n",
    "                        'game_index': i,\n",
    "                        'team': team,\n",
    "                        'market': market,\n",
    "                        'stake': stake\n",
    "                    }\n",
    "                    actions.append(action)\n",
    "    return actions\n",
    "\n",
    "# Load the trained agent and perform inference\n",
    "\n",
    "# Step 1: Load the trained agent\n",
    "# Replace 'state_size' and 'action_size' with the values used during training\n",
    "\n",
    "state_size = (15 * 2 * 4) + 1  # 15 games, 2 teams, 4 features per team, plus bankroll\n",
    "\n",
    "# We need to determine the action size as used during training\n",
    "# For that, we need to generate actions for a sample data to get the action size\n",
    "\n",
    "# Sample data to determine action size\n",
    "sample_data = {\n",
    "    'DATE': ['2024-11-16'] * 30,\n",
    "    'GAME-ID': [i // 2 for i in range(30)],\n",
    "    'TEAM': ['Team' + str(i) for i in range(30)],\n",
    "    'ml_prob': np.random.rand(30),\n",
    "    'ml_result': np.random.choice([True, False], 30),\n",
    "    'MONEYLINE': np.random.randint(-200, 200, 30),\n",
    "    'spread_prob': np.random.rand(30),\n",
    "    'spread_result': np.random.choice([True, False], 30),\n",
    "    'SPREAD_LINE': np.random.randint(-110, 110, 30),\n",
    "}\n",
    "sample_df = pd.DataFrame(sample_data)\n",
    "actions = generate_actions(sample_df)\n",
    "action_size = len(actions)\n",
    "\n",
    "# Create the agent\n",
    "agent = ParlaysDQNAgent(\n",
    "    state_size=state_size,\n",
    "    action_size=action_size,\n",
    "    batch_size=64,\n",
    "    gamma=0.99,\n",
    "    epsilon_start=0.0,  # Set epsilon to 0 for inference\n",
    "    epsilon_end=0.0,\n",
    "    epsilon_decay=1.0,\n",
    "    learning_rate=0.001,\n",
    "    target_update=10,\n",
    "    memory_size=10000,\n",
    "    logging_level=logging.INFO\n",
    ")\n",
    "\n",
    "# Load the trained model weights\n",
    "agent.load_model('parlays_dqn_model_1.pth')  # Replace with the path to your saved model\n",
    "\n",
    "# Step 2: Prepare today's game data and state\n",
    "\n",
    "# Replace 'today_games.csv' with your actual data file or DataFrame\n",
    "# Ensure that the DataFrame has all required columns and correct data types\n",
    "today_games_df = today_results\n",
    "today_games_df['SPREAD_LINE'] = -110\n",
    "# Ensure required columns are present\n",
    "required_columns = [\n",
    "    'DATE', 'GAME-ID', 'TEAM', 'ml_prob', 'MONEYLINE',\n",
    "    'spread_prob', 'SPREAD_LINE'\n",
    "]\n",
    "if not all(col in today_games_df.columns for col in required_columns):\n",
    "    raise ValueError(\"Missing required columns in today's game data.\")\n",
    "\n",
    "# Set the agent's bankroll\n",
    "agent.bankroll = 100  # Set your current bankroll\n",
    "\n",
    "# Prepare the state\n",
    "state = get_state(today_games_df, agent.bankroll, max_games=15)\n",
    "\n",
    "# Step 3: Generate available actions\n",
    "actions = generate_actions(today_games_df)\n",
    "action_size = len(actions)\n",
    "available_actions = list(range(action_size))\n",
    "\n",
    "# Step 4: Use the agent to select actions\n",
    "action_idx, q_values = agent.act(state, available_actions)\n",
    "action = actions[action_idx]\n",
    "\n",
    "# If you wish to select the top N actions\n",
    "N = 10  # Number of top actions to select\n",
    "top_N_action_indices = np.argsort(q_values)[-N:][::-1]\n",
    "\n",
    "# Step 5: Interpret and output the selected actions\n",
    "for idx in top_N_action_indices:\n",
    "    action = actions[idx]\n",
    "    stake_amount = action['stake'] * agent.bankroll\n",
    "    team = action['team']\n",
    "    market = action['market']\n",
    "    game_index = action['game_index']\n",
    "    \n",
    "    # Get the actual game ID for clarity\n",
    "    game_ids = today_games_df['GAME-ID'].unique()\n",
    "    if game_index < len(game_ids):\n",
    "        game_id = game_ids[game_index]\n",
    "    else:\n",
    "        game_id = 'Unknown'\n",
    "    \n",
    "    print(f\"Selected Action (Q-value: {q_values[idx]:.2f}):\")\n",
    "    print(f\"Bet ${stake_amount:.2f} on {team} in game {game_id}, market: {market}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIP PArlays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pulp import *\n",
    "\n",
    "# Create the problem instance\n",
    "model = LpProblem(\"Optimal_Parlays\", LpMaximize)\n",
    "\n",
    "# Example data\n",
    "legs = range(20)  # 10 legs available\n",
    "probabilities = {l: np.random.uniform(0.2, 0.8) for l in legs}  # Probabilities for each leg\n",
    "odds = {l: 2.0 for l in legs}  # Example odds (flat 2x payout)\n",
    "opposing_pairs = [(0, 1), (2, 3)]  # Define opposing bets\n",
    "parlays = range(10)  # Build up to 5 parlays\n",
    "alpha = 10  # Scaling factor for exposure\n",
    "k = 7  # Number of legs per parlay\n",
    "\n",
    "wager_per_parlay = 10  # Fixed wager per parlay\n",
    "budget = len(parlays) * wager_per_parlay  # Total budget for all parlays\n",
    "# Decision variables\n",
    "x = LpVariable.dicts(\"x\", [(p, l) for p in parlays for l in legs], cat=\"Binary\")\n",
    "y = LpVariable.dicts(\"y\", parlays, cat=\"Binary\")\n",
    "\n",
    "# Objective: Maximize expected profit\n",
    "model += lpSum(\n",
    "    y[p] * lpSum(probabilities[l] * (odds[l] - 1) for l in legs if x[p, l])\n",
    "    for p in parlays\n",
    ")\n",
    "\n",
    "# Constraints\n",
    "\n",
    "# Each parlay has exactly k legs\n",
    "for p in parlays:\n",
    "    model += lpSum(x[p, l] for l in legs) == k\n",
    "\n",
    "# Exposure constraint proportional to probability\n",
    "for l in legs:\n",
    "    model += lpSum(x[p, l] for p in parlays) <= alpha * probabilities[l]\n",
    "\n",
    "# Budget constraint\n",
    "model += lpSum(y[p] * wager_per_parlay for p in parlays) <= budget\n",
    "\n",
    "# Leg inclusion only if parlay is selected\n",
    "for p in parlays:\n",
    "    for l in legs:\n",
    "        model += x[p, l] <= y[p]\n",
    "\n",
    "# Opposing bets constraint\n",
    "for p in parlays:\n",
    "    for (l1, l2) in opposing_pairs:\n",
    "        model += x[p, l1] + x[p, l2] <= 1\n",
    "\n",
    "# Solve the model\n",
    "model.solve(PULP_CBC_CMD())\n",
    "\n",
    "# Output results\n",
    "print(\"Status:\", LpStatus[model.status])\n",
    "for p in parlays:\n",
    "    if y[p].varValue > 0:\n",
    "        selected_legs = [l for l in legs if x[p, l].varValue > 0]\n",
    "        print(f\"Parlay {p}: Legs {selected_legs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  nba_infer CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NORMALIZED PREDICTED WINNERS\\n')\n",
    "display(today_results[(today_results['spread_prob_normed'] > 0.5) & (today_results['spread_prob'] > 0.5)] \\\n",
    ".sort_values('spread_prob', ascending=False)[['TEAM', 'Opponent','CLOSING_SPREAD',\n",
    "                                                'spread_prob', 'spread_prob_normed', 'spread_kelly', 'spread_implied_prob']].drop_duplicates(subset=['TEAM']))\n",
    "\n",
    "print('\\nALL PREDICTED WINNERS\\n')\n",
    "today_results[(today_results['spread_prob_normed'] > 0.5)] \\\n",
    ".sort_values('spread_prob', ascending=False)[['TEAM', 'Opponent','CLOSING_SPREAD',\n",
    "                                                'spread_prob', 'spread_prob_normed']].drop_duplicates(subset=['TEAM'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('NORMALIZED PREDICTED WINNERS\\n')\n",
    "display(today_results[(today_results['ml_prob_normed'] > 0.5) & (today_results['ml_prob'] > 0.5)] \\\n",
    ".sort_values('ml_prob', ascending=False)[['TEAM', 'Opponent','MONEYLINE',\n",
    "                                                'ml_prob', 'ml_prob_normed']].drop_duplicates(subset=['TEAM']))\n",
    "\n",
    "print('ALL PREDICTED WINNERS\\n')\n",
    "display(today_results[(today_results['ml_prob_normed'] > 0.5)] \\\n",
    ".sort_values('ml_prob', ascending=False)[['TEAM', 'Opponent','MONEYLINE',\n",
    "                                                'ml_prob', 'ml_prob_normed']].drop_duplicates(subset=['TEAM']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_df['lambda'] = over_df.apply(\n",
    "    lambda row: solve_poisson_for_over(\n",
    "        k=int(row['CLOSING_TOTAL']), \n",
    "        p=float(row['total_prob'])\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Now df[\"lambda\"] holds the Poisson λ that gives P(X >= TOTAL) = prob for each row.\n",
    "over_df[['TEAM', 'Opponent','CLOSING_TOTAL', 'total_prob', 'lambda']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def logaddexp(a, b):\n",
    "    \"\"\"\n",
    "    Equivalent to math.log(math.exp(a) + math.exp(b)), \n",
    "    but numerically stable for large or very negative values.\n",
    "    \"\"\"\n",
    "    if a == b:\n",
    "        return a + math.log(2)\n",
    "    elif a > b:\n",
    "        return a + math.log1p(math.exp(b - a))\n",
    "    else:\n",
    "        return b + math.log1p(math.exp(a - b))\n",
    "\n",
    "\n",
    "def log_poisson_pmf(lam, i):\n",
    "    \"\"\"\n",
    "    log( P(X=i) ) for a Poisson(lam), i.e.:\n",
    "    log( e^(-lam) * lam^i / i! )\n",
    "    = -lam + i*log(lam) - logGamma(i+1)\n",
    "    \"\"\"\n",
    "    return -lam + i * math.log(lam) - math.lgamma(i+1)\n",
    "\n",
    "def log_poisson_cdf(lam, k):\n",
    "    \"\"\"\n",
    "    Returns log( P(X <= k) ) for X ~ Poisson(lam).\n",
    "    We do a sum of pmf(i) from i=0..k, all in log-space:\n",
    "        sum_{i=0..k} exp( log_poisson_pmf(lam, i) )\n",
    "    and keep a running log-sum with math.logaddexp to avoid overflow.\n",
    "    \"\"\"\n",
    "    log_sum = float('-inf')\n",
    "    for i in range(k+1):\n",
    "        lp = log_poisson_pmf(lam, i)\n",
    "        # logaddexp(a, b) = log( exp(a) + exp(b) )\n",
    "        log_sum = logaddexp(log_sum, lp)\n",
    "    return log_sum  # This is log of the actual CDF\n",
    "\n",
    "def solve_poisson_for_over(k, p, lower=1e-9, upper=3000, tol=1e-7):\n",
    "    \"\"\"\n",
    "    Find λ so that P(X >= k) = p for X ~ Poisson(λ),\n",
    "    which means P(X <= k-1) = 1 - p.\n",
    "\n",
    "    - k: integer threshold\n",
    "    - p: desired probability P(X >= k)\n",
    "    - lower, upper: bracket for λ\n",
    "    - tol: numerical tolerance\n",
    "\n",
    "    Returns: λ that solves Poisson(λ) with P(X >= k)=p,\n",
    "             or raises ValueError if no root in [lower, upper].\n",
    "    \"\"\"\n",
    "    # We want CDF(k-1) = 1 - p\n",
    "    target_cdf = 1 - p\n",
    "    \n",
    "    def f(lam):\n",
    "        # log(CDF) for X <= k-1\n",
    "        log_cdf_val = log_poisson_cdf(lam, k-1)  # log of sum_{i=0..k-1} pmf(i)\n",
    "        cdf_val = math.exp(log_cdf_val)\n",
    "        return cdf_val - target_cdf\n",
    "    \n",
    "    # Check boundary signs\n",
    "    f_low = f(lower)\n",
    "    f_high = f(upper)\n",
    "    if abs(f_low) < 1e-15:\n",
    "        return lower\n",
    "    if abs(f_high) < 1e-15:\n",
    "        return upper\n",
    "    if f_low * f_high > 0:\n",
    "        raise ValueError(\"No sign change in [lower, upper]; adjust bounds.\")\n",
    "    \n",
    "    # Bisection loop\n",
    "    while (upper - lower) > tol:\n",
    "        mid = 0.5*(lower + upper)\n",
    "        fm = f(mid)\n",
    "        if fm == 0:\n",
    "            return mid\n",
    "        if fm * f_low < 0:\n",
    "            upper = mid\n",
    "            f_high = fm\n",
    "        else:\n",
    "            lower = mid\n",
    "            f_low = fm\n",
    "    return 0.5 * (lower + upper)\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Suppose we want P(X >= 210) = 0.8\n",
    "    threshold = 230\n",
    "    prob = 0.97\n",
    "    lam_est = solve_poisson_for_over(threshold, prob)\n",
    "    print(f\"λ ≈ {round(lam_est*2)/2} so that P(X >= {threshold}) = {prob} for Poisson(λ).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nba_2024 CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Predict on x_test\n",
    "y_pred = pts_model.predict(X_test.drop('GAME-ID', axis=1))\n",
    "\n",
    "# Step 2: Create a DataFrame with predictions and actual values\n",
    "pred_df = pd.DataFrame({\n",
    "    'Predicted_PTS': y_pred,\n",
    "    'Actual_PTS': y_test\n",
    "})\n",
    "\n",
    "\n",
    "# Step 3: Calculate error\n",
    "pred_df['Prediction_Error'] = abs(pred_df['Predicted_PTS'] - pred_df['Actual_PTS'])\n",
    "\n",
    "# Step 4: Check if the predicted points meet or exceed the player prop line\n",
    "pred_df['Prediction_Met'] = pred_df['Predicted_PTS'] >= pred_df['Actual_PTS']\n",
    "\n",
    "# Step 5: Define bins based on prediction magnitude (e.g., every 5 points)\n",
    "pred_df['Prediction_Bin'] = pd.cut(pred_df['Predicted_PTS'], bins=10)\n",
    "\n",
    "# Step 6: Calculate accuracy within each bin\n",
    "bin_accuracy = pred_df.groupby('Prediction_Bin')['Prediction_Met'].mean().reset_index()\n",
    "bin_accuracy.columns = ['Prediction_Bin', 'Accuracy']\n",
    "\n",
    "# Step 7: Plot a histogram of accuracy by prediction magnitude bin\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(bin_accuracy['Prediction_Bin'].astype(str), bin_accuracy['Accuracy'] * 100)\n",
    "\n",
    "# Annotate bars with actual accuracy values\n",
    "for bar, accuracy in zip(bars, bin_accuracy['Accuracy']):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
    "             f'{accuracy * 100:.2f}%', ha='center', va='bottom')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Prediction Magnitude (Binned)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Prediction Accuracy by Prediction Magnitude')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
